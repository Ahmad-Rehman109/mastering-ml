import json
import csv
import time
import requests
from bs4 import BeautifulSoup

all_data = []

#Change range to desired page range e.g range(1,20)

for page in range(1):
    url = "https://www.ebay.com/sch/i.html?_nkw=gpu&_sacat=0&_from=R40&_pgn={page}"

    response = requests.get(url)
    if response.status_code != 200:
        raise Exception(print(f"Abnormal Status Code {response.status_code}"))

    soup = BeautifulSoup(response.text, 'html.parser')
    time.sleep(2)
    items = soup.find_all('li', class_ = 's-item s-item__pl-on-bottom')

    for item in items:
        title_box = item.find('div', class_ = 's-item__title')
        title = title_box.get_text(strip=True)
        
        subtitle_div = item.find('div', class_ = 's-item__subtitle')
        subtitle = subtitle_div.get_text(separator=' ', strip=True)
        
        price_element = item.find('span',class_ = 's-item__price') 
        price = price_element.text.strip() if price_element else 'N/A'
        
        shipping_element = item.find('span', class_ = 's-item__shipping s-item__logisticsCost')
        shipping = shipping_element.text.strip() if shipping_element else 'N/A'

        saving_element = item.find('span',class_ = 'NEGATIVE BOLD')
        savings = saving_element.text.strip() if saving_element else 'No SavingsðŸ˜²'

        link_element = item.find('a', class_='s-item__link')
        link = link_element.get('href') if link_element else 'N/A'

        info = ({
            'Title' : title ,
            'Subtitle' : subtitle ,
            'Price' : price ,
            'Shipping' : shipping ,
            'Savings' : savings ,
            'Link' : link
        })
        all_data.append(info)
        

with open('ebay_laptops.csv', 'w', newline='', encoding='utf-8')as f_csv:
    writer = csv.DictWriter(f_csv, fieldnames=['Title', 'Subtitle', 'Price', 'Shipping', 'Savings', 'Link'])
    writer.writeheader()
    writer.writerows(all_data)
    
